{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73bc2edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshua/miniconda3/envs/llm-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM\n",
    "import gradio as gr\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af469bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "#model_path = \"/mnt/models/llm_storage/Phi-4-mini-instruct\"\n",
    "#model_path = \"/home/joshua/llms/llama3.1_PC_Build/Llama-3.1-8B-Instruct\"\n",
    "model_path = \"/mnt/models/llm_storage/Llama-3.2-3B-Instruct\"\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path, \n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ea987",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_context = {\n",
    "    \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are SMARTConnect V2, a helpful and strategic AI assistant created to help small businesses discover ideal partnerships. \"\n",
    "            \"You dont know there business or anbything about them until they tell you. \"\n",
    "            \"Your goal is to help them find the best partnerships for their business. \"\n",
    "            \"Ask relevant business questions first, and only generate partner recommendations and outreach emails once you have complete information.\"\n",
    "        )\n",
    "}\n",
    "\n",
    "bot_context = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": (\n",
    "            \"When the user initiates the conversation, begin by asking them to describe their business. \"\n",
    "            \"Ask for what the bussiness is name and there primary purpose. \"\n",
    "            \"Prompt them to explain what their company does and what kinds of products or services they offer. \"\n",
    "            \"This will help lay the foundation for a personalized recommendation.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": (\n",
    "            \"Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. \"\n",
    "            \"Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide \"\n",
    "            \"(e.g. support, warranties, repairs), and whether they operate online, in-store, or both. \"\n",
    "            \"These details will help you tailor your recommendations more precisely.\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "final_context = {\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": (\n",
    "        \"Once the user has provided complete details about their business, prepare to generate your recommendations. \"\n",
    "        \"Clearly indicate to the user that you're now creating the output. \"\n",
    "        \"List the top 3 most complementary business categories for partnerships based on the users information. \"\n",
    "        \"For each complementary business list a reason, 2-3 strategic benefits, and a professional outreach email template. \"\n",
    "    )\n",
    "}\n",
    "\n",
    "def format_messages(messages):\n",
    "    prompt = \"\"\n",
    "    for msg in messages:\n",
    "        role = msg[\"role\"]\n",
    "        if role == \"system\":\n",
    "            prompt += f\"<|system|>\\n{msg['content']}\\n\"\n",
    "        elif role == \"user\":\n",
    "            prompt += f\"<|user|>\\n{msg['content']}\\n\"\n",
    "        elif role == \"assistant\":\n",
    "            prompt += f\"<|assistant|>\\n{msg['content']}\\n\"\n",
    "    prompt += \"<|assistant|>\\n\"\n",
    "    return prompt\n",
    "\n",
    "# outputs = pipeline(\n",
    "#     prompt, \n",
    "#     max_new_tokens=2000,\n",
    "#     length_penalty=1,\n",
    "#     num_beams=6,\n",
    "#     temperature=0.1,\n",
    "#     top_p=0.8,\n",
    "#     repetition_penalty=1,\n",
    "#     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce76d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(messages, max_new_tokens):\n",
    "    prompt = format_messages(messages)\n",
    "    #print(prompt)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        #top_p=0.95,\n",
    "        #repetition_penalty=1.1,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response.split(\"<|assistant|>\")[-1]\n",
    "\n",
    "def check_for_relevant_info(user_input, expected_question):\n",
    "    relevance_check_context = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a strict assistant that determines whether a user's input is directly relevant to a specific question. \"\n",
    "                \"You only respond with 'Yes' or 'No'. If the input very clearly addresses the question, say 'Yes'. \"\n",
    "                \"If the input is vague, unrelated, or off-topic, say 'No'.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Question: {expected_question}\\nUser Input: {user_input}\\nIs the user input relevant to the question?\"\n",
    "        }\n",
    "    ]\n",
    "    response = generate_response(relevance_check_context, max_new_tokens=100)\n",
    "    print(f\"User input: {user_input}\")\n",
    "    print(f\"Expected question: {expected_question}\")\n",
    "    print(f\"Relevance check response: {response}\")\n",
    "    return \"yes\" in response.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd391fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:7813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshua/miniconda3/envs/llm-env/lib/python3.10/site-packages/gradio/analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.37.2, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on public URL: https://7cdb3ccce495673253.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7cdb3ccce495673253.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: Oh Hi I currently run a PC building Business called MASTER RACERS\n",
      "Expected question: When the user initiates the conversation, begin by asking them to describe their business. Ask for what the bussiness is name and there primary purpose. Prompt them to explain what their company does and what kinds of products or services they offer. This will help lay the foundation for a personalized recommendation.\n",
      "Relevance check response: \n",
      "No. The user input is a statement about their business, but it doesn't address the question of laying the foundation for a personalized recommendation. It's a brief introduction to their business.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: Oh Hi I currently run a PC building Business called MASTER RACERS\n",
      "Expected question: When the user initiates the conversation, begin by asking them to describe their business. Ask for what the bussiness is name and there primary purpose. Prompt them to explain what their company does and what kinds of products or services they offer. This will help lay the foundation for a personalized recommendation.\n",
      "Relevance check response: \n",
      "Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: POP\n",
      "Expected question: Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide (e.g. support, warranties, repairs), and whether they operate online, in-store, or both. These details will help you tailor your recommendations more precisely.\n",
      "Relevance check response: \n",
      "No.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: POP\n",
      "Expected question: Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide (e.g. support, warranties, repairs), and whether they operate online, in-store, or both. These details will help you tailor your recommendations more precisely.\n",
      "Relevance check response: \n",
      "No\n",
      "The user input 'POP' is too vague and does not address the question about understanding the user's business operation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: POP\n",
      "Expected question: Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide (e.g. support, warranties, repairs), and whether they operate online, in-store, or both. These details will help you tailor your recommendations more precisely.\n",
      "Relevance check response: \n",
      "No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: POP\n",
      "Expected question: Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide (e.g. support, warranties, repairs), and whether they operate online, in-store, or both. These details will help you tailor your recommendations more precisely.\n",
      "Relevance check response: \n",
      "No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: POP\n",
      "Expected question: Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide (e.g. support, warranties, repairs), and whether they operate online, in-store, or both. These details will help you tailor your recommendations more precisely.\n",
      "Relevance check response: \n",
      "No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: POP\n",
      "Expected question: Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide (e.g. support, warranties, repairs), and whether they operate online, in-store, or both. These details will help you tailor your recommendations more precisely.\n",
      "Relevance check response: \n",
      "No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: POP\n",
      "Expected question: Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide (e.g. support, warranties, repairs), and whether they operate online, in-store, or both. These details will help you tailor your recommendations more precisely.\n",
      "Relevance check response: \n",
      "No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: POP\n",
      "Expected question: Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide (e.g. support, warranties, repairs), and whether they operate online, in-store, or both. These details will help you tailor your recommendations more precisely.\n",
      "Relevance check response: \n",
      "No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: POP\n",
      "Expected question: Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide (e.g. support, warranties, repairs), and whether they operate online, in-store, or both. These details will help you tailor your recommendations more precisely.\n",
      "Relevance check response: \n",
      "No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: POP\n",
      "Expected question: Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide (e.g. support, warranties, repairs), and whether they operate online, in-store, or both. These details will help you tailor your recommendations more precisely.\n",
      "Relevance check response: \n",
      "No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: POP\n",
      "Expected question: Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide (e.g. support, warranties, repairs), and whether they operate online, in-store, or both. These details will help you tailor your recommendations more precisely.\n",
      "Relevance check response: \n",
      "No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: POP\n",
      "Expected question: Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide (e.g. support, warranties, repairs), and whether they operate online, in-store, or both. These details will help you tailor your recommendations more precisely.\n",
      "Relevance check response: \n",
      "No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: POP\n",
      "Expected question: Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide (e.g. support, warranties, repairs), and whether they operate online, in-store, or both. These details will help you tailor your recommendations more precisely.\n",
      "Relevance check response: \n",
      "<|system|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: POP\n",
      "Expected question: Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide (e.g. support, warranties, repairs), and whether they operate online, in-store, or both. These details will help you tailor your recommendations more precisely.\n",
      "Relevance check response: \n",
      "No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: POP\n",
      "Expected question: Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide (e.g. support, warranties, repairs), and whether they operate online, in-store, or both. These details will help you tailor your recommendations more precisely.\n",
      "Relevance check response: \n",
      "No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: POP\n",
      "Expected question: Once the user has shared their business overview, follow up with more specific questions to fully understand their operation. Ask about their typical customer base (e.g. individuals, schools, small businesses), any accessories or services they provide (e.g. support, warranties, repairs), and whether they operate online, in-store, or both. These details will help you tailor your recommendations more precisely.\n",
      "Relevance check response: \n",
      "No\n"
     ]
    }
   ],
   "source": [
    "load_context = [system_context] \n",
    "chat_stage = 0 \n",
    "\n",
    "\n",
    "def smartconnect_chat(user_input):\n",
    "    global chat_stage, load_context\n",
    "\n",
    "    if user_input.strip().upper() == \"RESET\":\n",
    "        load_context = [system_context]\n",
    "        chat_stage = 0\n",
    "        return \"SMARTConnect V2: Memory cleared! Please type 'START' to begin again.\"\n",
    "\n",
    "    if user_input.strip().upper() == \"START\" and chat_stage == 0:\n",
    "        load_context.append({\"role\": \"user\", \"content\": bot_context[0]['content']})\n",
    "        chat_response = generate_response(load_context, 400)\n",
    "        load_context.append({\"role\": \"assistant\", \"content\": chat_response})\n",
    "        chat_stage += 1\n",
    "        return f\"SMARTConnect V2: {chat_response}\"\n",
    "\n",
    "    elif 0 < chat_stage <= len(bot_context):\n",
    "        expected_question = bot_context[chat_stage - 1]['content']\n",
    "        if not check_for_relevant_info(user_input, expected_question):\n",
    "            return \"SMARTConnect V2: Let's stay on topic. Please rephrase your answer to better match the current question.\"\n",
    "\n",
    "        load_context.append({\"role\": \"user\", \"content\": user_input})\n",
    "        if chat_stage < len(bot_context):\n",
    "            chat_response = generate_response(load_context, 400)\n",
    "            load_context.append({\"role\": \"assistant\", \"content\": chat_response})\n",
    "            chat_stage += 1\n",
    "            return f\"SMARTConnect V2: {chat_response}\"\n",
    "\n",
    "        else:\n",
    "            load_context.append(final_context)\n",
    "            final_response = generate_response(load_context, 2000)\n",
    "            chat_stage += 1\n",
    "            return f\"SMARTConnect V2:\\n\\n{final_response}\"\n",
    "\n",
    "    else:\n",
    "        return \"SMARTConnect V2: Thank you! If you wish to restart, refresh the page.\"\n",
    "\n",
    "gr.Interface(\n",
    "    fn=smartconnect_chat,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Type 'START' to begin\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"SMARTConnect V2 - Business Partnership Finder\",\n",
    "    description=\"Say 'START' to begin the business discovery process. Type 'RESET' anytime to restart.\"\n",
    ").launch(server_name=\"0.0.0.0\", server_port=781, share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc09a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:7869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshua/miniconda3/envs/llm-env/lib/python3.10/site-packages/gradio/analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.37.2, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on public URL: https://9905d7fe06cc7226fc.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9905d7fe06cc7226fc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "/home/joshua/miniconda3/envs/llm-env/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/joshua/miniconda3/envs/llm-env/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# === Load flow JSON ===\n",
    "with open(\"chat_flow.json\") as f:\n",
    "    chat_flow = json.load(f)\n",
    "\n",
    "system_context = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": (\n",
    "        \"You are SMARTConnect V2, a helpful AI assistant. Your job is to guide users through a structured discovery conversation \"\n",
    "        \"about their business. If a user asks something unrelated, answer it briefly and then return to the current business question.\"\n",
    "    )\n",
    "}\n",
    "\n",
    "state_index = 0\n",
    "chat_history = [system_context]\n",
    "\n",
    "# === Format messages for LLaMA-style prompt ===\n",
    "def format_prompt(messages):\n",
    "    prompt = \"\"\n",
    "    for msg in messages:\n",
    "        prompt += f\"<|{msg['role']}|>\\n{msg['content']}\\n\"\n",
    "    prompt += \"<|assistant|>\\n\"\n",
    "    return prompt\n",
    "\n",
    "# === Inference ===\n",
    "def generate_response(messages, max_new_tokens=400):\n",
    "    prompt = format_prompt(messages)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return decoded.split(\"<|assistant|>\")[-1].strip()\n",
    "\n",
    "def is_question_answered(user_input, validation_hint):\n",
    "    check_prompt = (\n",
    "        f\"<|system|>\\n\"\n",
    "        f\"You are a strict validator. Only reply with 'yes' or 'no'.\\n\"\n",
    "        f\"Determine if this response answers the assistantâ€™s current question.\\n\"\n",
    "        f\"The required answer should: {validation_hint}\\n\"\n",
    "        f\"User said: \\\"{user_input}\\\"\\n\"\n",
    "        f\"<|assistant|>\\n\"\n",
    "        f\"yes or no:\"\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(check_prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=2,\n",
    "        do_sample=False,\n",
    "        temperature=0.0,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True).lower().strip()\n",
    "    return decoded.startswith(\"yes\")\n",
    "\n",
    "\n",
    "# === Gradio Chat Function ===\n",
    "def smartconnect_chat(user_input):\n",
    "    global state_index, chat_history\n",
    "\n",
    "    if user_input.strip().upper() == \"RESET\":\n",
    "        chat_history = [system_context]\n",
    "        state_index = 0\n",
    "        return \"ðŸ”„ Chat reset. Let's begin. \" + chat_flow[0][\"prompt\"]\n",
    "\n",
    "    if state_index >= len(chat_flow):\n",
    "        return \"âœ… All questions completed. Type 'RESET' to restart.\"\n",
    "\n",
    "    # Get current question\n",
    "    current_prompt = chat_flow[state_index][\"prompt\"]\n",
    "\n",
    "    # Add user input to history\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Add assistant's planned question (as reminder to LLM)\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": current_prompt})\n",
    "\n",
    "    # Generate response\n",
    "    model_reply = generate_response(chat_history)\n",
    "\n",
    "    validation_hint = chat_flow[state_index].get(\"validation_hint\", \"\")\n",
    "    if is_question_answered(user_input, validation_hint):\n",
    "        state_index += 1\n",
    "        if state_index < len(chat_flow):\n",
    "            next_prompt = chat_flow[state_index][\"prompt\"]\n",
    "            chat_history.append({\"role\": \"assistant\", \"content\": next_prompt})\n",
    "            return model_reply + \"\\n\\n**Next question:** \" + next_prompt\n",
    "        else:\n",
    "            return model_reply + \"\\n\\nâœ… You're done! Type 'RESET' to restart.\"\n",
    "    else:\n",
    "        return model_reply + \"\\n\\nðŸ” Please try answering the question more directly.\"\n",
    "\n",
    "\n",
    "# === Launch Gradio ===\n",
    "gr.Interface(\n",
    "    fn=smartconnect_chat,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Say hi or type 'RESET'\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"SMARTConnect V2 â€“ Business Discovery Assistant\",\n",
    "    description=\"Guided by JSON, answered by your local LLaMA model. Type 'RESET' anytime to restart.\",\n",
    ").launch(server_name=\"0.0.0.0\", server_port=7869, share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad163bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b510b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMARTConnect V2: This is a business connection tool for Small Tech Businesses, say START to begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMARTConnect V2: Alright lets begin!\n",
      "\n",
      "SMARTConnect V2:\n",
      "Another question to help me better understand your business: What industries or sectors is your business primarily operating in? For example, is it healthcare, finance, retail, technology, or something else? This will help me provide more targeted and relevant partnership suggestions.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'display_in_browser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#print(f\"\\nDebug - Loading Context:\\n{i}\\n\")\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSMARTConnect V2:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mchat_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mdisplay_in_browser\u001b[49m(chat_response)\n\u001b[1;32m     15\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m load_context\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_input})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'display_in_browser' is not defined"
     ]
    }
   ],
   "source": [
    "# load_context = [system_context]\n",
    "\n",
    "# print(\"SMARTConnect V2: This is a business connection tool for Small Tech Businesses, say START to begin\")\n",
    "# while user_input != \"START\":\n",
    "#     user_input = input(\"You: \")\n",
    "\n",
    "# print(\"SMARTConnect V2: Alright lets begin!\")\n",
    "# for i in range(len(bot_context)):\n",
    "#     load_context.append(bot_context[i])\n",
    "#     chat_response = generate_response(load_context, 400)\n",
    "#     #print(f\"\\nDebug - Loading Context:\\n{i}\\n\")\n",
    "#     print(f\"\\nSMARTConnect V2:\\n{chat_response}\\n\")\n",
    "    \n",
    "#     user_input = input(\"You: \")\n",
    "#     load_context.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "# print(\"\\nSMARTConnect V2 is generating your tailored recommendations...\\n\")\n",
    "# load_context.append(final_context)\n",
    "# final_response = generate_response(load_context, 2000)\n",
    "# print(f\"\\nSMARTConnect V2:\\n{final_response}\\n\")\n",
    "\n",
    "# OUTPUT EXAMPLE\n",
    "# SMARTConnect V2:\n",
    "\n",
    "# Based on our conversation, I recommend the following top 3 business categories for partnerships:\n",
    "\n",
    "# **1. Local Food Suppliers**\n",
    "\n",
    "# Reason: Aligning with your focus on quality and sustainability, partnering with local food suppliers can ensure consistent freshness and reduce carbon footprint.\n",
    "\n",
    "# Strategic Benefits:\n",
    "\n",
    "# * Secure access to high-quality ingredients\n",
    "# * Support local businesses and contribute to community development\n",
    "# * Enhance your brand's reputation for sustainability\n",
    "\n",
    "# Outreach Email Template:\n",
    "\n",
    "# Subject: Exploring Partnership Opportunities for Fresh Ingredients\n",
    "\n",
    "# Dear [Supplier's Name],\n",
    "\n",
    "# I hope this email finds you well. As a cooking business focused on delivering quality meals, I'm excited to explore potential partnership opportunities with your local food supplier company. Our shared commitment to sustainability and quality aligns perfectly with your business model.\n",
    "\n",
    "# Would you be open to discussing how we can work together to source fresh, locally-sourced ingredients for our customers? I believe our collaboration could bring numerous benefits to both our businesses.\n",
    "\n",
    "# Looking forward to hearing from you.\n",
    "\n",
    "# Best regards,\n",
    "# [Your Name]\n",
    "\n",
    "# **2. Kitchen Appliance Brands**\n",
    "\n",
    "# Reason: Partnering with kitchen appliance brands can enhance your business's reputation for quality and provide customers with integrated solutions.\n",
    "\n",
    "# Strategic Benefits:\n",
    "\n",
    "# * Offer bundled solutions with appliances and cooking services\n",
    "# * Enhance your brand's reputation for quality and expertise\n",
    "# * Access to innovative appliances and cooking technologies\n",
    "\n",
    "# Outreach Email Template:\n",
    "\n",
    "# Subject: Partnership Opportunities for Integrated Cooking Solutions\n",
    "\n",
    "# Dear [Appliance Brand's Name],\n",
    "\n",
    "# I'm reaching out to explore potential partnership opportunities between our cooking business and your kitchen appliance brand. Our shared passion for quality and innovation aligns perfectly with your business model.\n",
    "\n",
    "# Would you be interested in discussing how we can collaborate to offer bundled solutions with our cooking services and your appliances? This could bring significant benefits to both our businesses, including enhanced customer satisfaction and increased brand visibility.\n",
    "\n",
    "# Looking forward to hearing from you.\n",
    "\n",
    "# Best regards,\n",
    "# [Your Name]\n",
    "\n",
    "# **3. Cooking Schools or Health and Wellness Brands**\n",
    "\n",
    "# Reason: Partnering with cooking schools or health and wellness brands can expand your customer base, enhance your brand's reputation, and offer new services.\n",
    "\n",
    "# Strategic Benefits:\n",
    "\n",
    "# * Access new customer segments and expand your business\n",
    "# * Collaborate on cooking classes, workshops, or events\n",
    "# * Enhance your brand's reputation for expertise and commitment to healthy eating\n",
    "\n",
    "# Outreach Email Template:\n",
    "\n",
    "# Subject: Exploring Partnership Opportunities for Cooking Classes and Events\n",
    "\n",
    "# Dear [Cooking School's Name],\n",
    "\n",
    "# I hope this email finds you well. As a cooking business focused on delivering quality meals, I'm excited to explore potential partnership opportunities with your cooking school. Our shared passion for cooking and healthy eating aligns perfectly with your business model.\n",
    "\n",
    "# Would you be interested in discussing how we can collaborate on cooking classes, workshops, or events that showcase our expertise and your school's offerings? This could bring numerous benefits to both our businesses, including expanded customer reach and enhanced brand visibility.\n",
    "\n",
    "# Looking forward to hearing from you.\n",
    "\n",
    "# Best regards,\n",
    "# [Your Name]\n",
    "\n",
    "# Which of these partnerships resonates with you the most, or would you like to explore other options?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
